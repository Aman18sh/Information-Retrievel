# Information-Retrievel Project

This project focuses on Data mining, Information Retrievel(NLP), and Stastical Modeling. The main is to extract, preprocess, and analyze text data from news articles to derive meaningful insights.

Project Overview:

The project is divided into three key subtasks:

1. Web scraping and CSV Conversion
- Extracting the required text data and meta data from the articles.
- Converting the extracted information into a stuctural CSV format

2. Text Processsing
- Performing text processing using various NLP techniques such as:
-   Lowercasing
-   Removing punctuation
-   Stopword removal
-   Text Correction
-   Tokenization
-   Stemming and Lemmatization
-   Vectorization
-   Standardizing Features
-   Detecting outliers

3. Text Analysis
- Text Summarization - summarizing text
- Word Frequency Analysis - Most common word in the text
- Sentiment Analysis - sentiment (positive, negative or neutral)

Libraries Used:

- Pandas: For data manipulation and storage in csv
- Numpy: For numerical operations
- sklearn: For text vectorization
- nltk: For preprocessing techniques such as tokenization, stopword removal, stemming and lemmatization.
- Huggingface Transformers: For NLP tasks such as text summarization, word frequency analysis and sentiment analysis.

